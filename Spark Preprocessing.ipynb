{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPx2Uc4-QCSu",
        "outputId": "563649d1-5645-4bb9-e76b-74470bac081b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,082 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,373 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,798 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,069 kB]\n",
            "Fetched 6,555 kB in 4s (1,474 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "51 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=a6c22faaa1bd1f7d1e4da88edc5f4bce7f5711d3c1a25600bcc8b990cdb4b03d\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"VideoFrameExtractor\").getOrCreate()\n",
        "\n",
        "# Function to count every 20th frame in a video\n",
        "def count_every_20th_frame(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_count = 0\n",
        "    selected_frame_count = 0  # Counter for every 20th frame\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if frame_count % 20 == 0:  # Check if it's the 20th frame\n",
        "            selected_frame_count += 1\n",
        "        frame_count += 1\n",
        "    cap.release()\n",
        "    return selected_frame_count\n",
        "\n",
        "# Function to process each folder of videos\n",
        "def process_folder(folder_path):\n",
        "    folder_name = os.path.basename(folder_path)\n",
        "    video_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path) if file.endswith(('.mp4', '.avi'))]\n",
        "    # Sum the counts of every 20th frame from each video in the folder\n",
        "    total_selected_frames = sum(count_every_20th_frame(video) for video in video_files)\n",
        "    return (folder_name, total_selected_frames)\n",
        "\n",
        "# List of folders to process\n",
        "folders = [\"Abuse\", \"Arson\", \"Arrest\",\"Burglary\",\"Assault\",\"Explosion\",\"Fighting\",\"Shoplifting\",\"Stealing\",\"Vandalism\",\"Robbery\",\"RoadAccident\",\"Shooting\",\"Banner\"]\n",
        "folder_paths = [os.path.join(\"/content\", folder) for folder in folders]  # Change \"/content\" to your dataset path\n",
        "\n",
        "# Create an RDD for folders\n",
        "folders_rdd = spark.sparkContext.parallelize(folder_paths, numSlices=len(folder_paths))\n",
        "\n",
        "# Map the folder processing function to the RDD\n",
        "folder_frame_counts = folders_rdd.map(process_folder)\n",
        "\n",
        "# Collecting results\n",
        "results = folder_frame_counts.collect()\n",
        "\n",
        "# Print results\n",
        "for result in results:\n",
        "    print(f\"Folder: {result[0]}, Total Selected Frame Count: {result[1]}\")\n",
        "\n",
        "# Stop Spark Session\n",
        "spark.stop()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34cRwd1ZTMN2",
        "outputId": "80bb6342-71bd-4069-e197-86654fca92a9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder: Abuse, Total Selected Frame Count: 8347\n",
            "Folder: Arson, Total Selected Frame Count: 5545\n",
            "Folder: Arrest, Total Selected Frame Count: 4837\n",
            "Folder: Burglary, Total Selected Frame Count: 10890\n",
            "Folder: Assault, Total Selected Frame Count: 4632\n",
            "Folder: Explosion, Total Selected Frame Count: 10460\n",
            "Folder: Fighting, Total Selected Frame Count: 16742\n",
            "Folder: Shoplifting, Total Selected Frame Count: 8664\n",
            "Folder: Stealing, Total Selected Frame Count: 6688\n",
            "Folder: Vandalism, Total Selected Frame Count: 7261\n",
            "Folder: Robbery, Total Selected Frame Count: 6356\n",
            "Folder: RoadAccident, Total Selected Frame Count: 3481\n",
            "Folder: Shooting, Total Selected Frame Count: 13565\n",
            "Folder: Banner, Total Selected Frame Count: 1900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "88peKJPLcccJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}